{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regularized logistic regression to classify email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Penalty experiments -----------\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-4.86311364] [[-2.74146453e-02 -2.25297590e-01  1.21840937e-01  2.29362873e+00\n",
      "   2.70425714e-01  2.32851165e-01  9.28595395e-01  2.95200239e-01\n",
      "   1.62205937e-01  6.78260459e-02 -8.32604430e-02 -1.60373355e-01\n",
      "  -4.72247658e-02  1.07677122e-02  1.87903329e-01  8.19771813e-01\n",
      "   5.09528969e-01  3.98711552e-02  2.67729697e-01  3.47047585e-01\n",
      "   2.60498922e-01  3.64605177e-01  7.25019558e-01  1.96728251e-01\n",
      "  -3.15395700e+00 -4.03133784e-01 -1.25451045e+01 -6.16581305e-02\n",
      "  -1.56114612e+00 -5.51429725e-02 -3.00815305e-02  4.07263522e-01\n",
      "  -3.68156440e-01 -1.43611777e+00 -5.87180486e-01  4.44294911e-01\n",
      "   4.23159437e-02 -1.56897094e-01 -4.55330850e-01 -1.02250295e-01\n",
      "  -3.54273293e+00 -1.72944491e+00 -4.37529284e-01 -1.05999941e+00\n",
      "  -9.18599334e-01 -1.75490331e+00 -1.67475860e-01 -9.56875228e-01\n",
      "  -3.65653126e-01 -1.36535504e-01 -6.58692477e-02  2.06714026e-01\n",
      "   1.70694383e+00  1.21460315e+00 -3.35269845e-01  1.56141398e+00\n",
      "   3.68775715e-01]]\n",
      "Accuracy on set aside test set for  std  =  0.9296875\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-4.89602534] [[-0.52657609 -0.25869424 -0.11861765  0.98377776  1.26444564  0.99484319\n",
      "   3.11636526  1.49824047  0.32088258  0.41430299 -0.60968795 -0.47840948\n",
      "  -0.85965235  0.41746558  0.76761505  1.59138158  1.54553737 -0.0642802\n",
      "   0.41099045  0.77259436  0.51055562  0.46034456  2.13944169  1.48285275\n",
      "  -3.67941209 -0.45239611 -9.91289026  0.18046914 -2.1699225   0.04495226\n",
      "  -0.01785406 -0.42987845 -1.02473304 -0.89688149 -1.78397793  1.64952272\n",
      "  -0.78464325 -0.48827434 -1.3424199  -0.40621089 -3.32753365 -3.47148895\n",
      "  -3.14818693 -2.89136969 -1.39061526 -3.20784855 -1.79365274 -4.17854462\n",
      "  -2.2992624  -0.90909685 -1.04695852  2.08644303  5.78598965  1.10328396\n",
      "   0.8289355   0.08161178  0.53186733]]\n",
      "Accuracy on set aside test set for  logt  =  0.94140625\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-0.41635253] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Accuracy on set aside test set for  bin  =  0.6126302083333334\n",
      "L1 Penalty experiments -----------\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-11.89720421] [[-5.32931436e-02 -2.02663168e-01  1.08851244e-01  2.86549191e+00\n",
      "   2.68848795e-01  2.59047638e-01  8.99746056e-01  2.98435217e-01\n",
      "   2.28553558e-01  6.95609341e-02 -6.90411607e-02 -1.54009255e-01\n",
      "  -3.29575793e-02  1.62248984e-02  1.62532130e-01  7.99252523e-01\n",
      "   5.35666015e-01  3.54226115e-02  2.68897107e-01  3.32753310e-01\n",
      "   2.54873147e-01  3.38440536e-01  6.95088426e-01  1.75044503e-01\n",
      "  -3.22504411e+00 -3.20777673e-01 -4.42604587e+01 -6.03469992e-02\n",
      "  -1.43196554e+00 -1.29874297e-02  1.78884743e-01  5.44997947e-01\n",
      "  -3.28606865e-01 -1.18170060e-01 -7.27998657e-01  4.34507138e-01\n",
      "   5.85448641e-02 -1.55521307e-01 -4.52555289e-01 -4.06924089e-02\n",
      "  -5.32516332e+00 -1.85223197e+00 -5.19385911e-01 -1.01196632e+00\n",
      "  -9.15893272e-01 -1.76665512e+00 -1.70131154e-01 -1.20571140e+00\n",
      "  -3.51982934e-01 -1.36312768e-01 -5.44537229e-02  1.98223545e-01\n",
      "   1.70986712e+00  1.09417781e+00  6.64213021e-02  2.57598086e+00\n",
      "   3.17069291e-01]]\n",
      "Accuracy on set aside test set for  std  =  0.92578125\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-5.01399678] [[ -0.54540638  -0.18218443  -0.12552119   0.94891176   1.27000501\n",
      "    1.11004285   3.1164918    1.47935391   0.48099242   0.50019709\n",
      "   -0.60608374  -0.46552871  -0.90914349   0.47812889   0.6047631\n",
      "    1.58999266   1.71743297  -0.09062948   0.41448823   0.85148342\n",
      "    0.51323454   0.47089815   2.2237592    1.40707421  -3.87806917\n",
      "   -0.30220415 -18.38373845   0.19976969  -2.50372087   0.\n",
      "    0.4527102    0.          -0.90873612   0.          -2.00026158\n",
      "    1.69361709  -0.65261788  -0.42845054  -1.40106641  -0.11076385\n",
      "   -9.39153143  -4.03357686  -3.93074754  -3.21008736  -1.49453463\n",
      "   -3.28402387  -2.39911898  -5.56952393  -2.44303695  -1.00599859\n",
      "   -0.76797315   2.09978921   6.62766209   1.12460912   0.79244845\n",
      "    0.06590597   0.58039555]]\n",
      "Accuracy on set aside test set for  logt  =  0.9388020833333334\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-0.41621275] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Accuracy on set aside test set for  bin  =  0.6126302083333334\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import utils\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "# No modifications in this script\n",
    "# complete the functions in util.py; then run the script\n",
    "\n",
    "# load the spam data in\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = utils.load_spam_data()\n",
    "\n",
    "# Preprocess the data \n",
    "\n",
    "Xtrain_std,mu,sigma = utils.std_features(Xtrain)\n",
    "Xtrain_logt = utils.log_features(Xtrain)\n",
    "Xtrain_bin = utils.bin_features(Xtrain)\n",
    "\n",
    "Xtest_std = (Xtest - mu)/sigma\n",
    "Xtest_logt = utils.log_features(Xtest)\n",
    "Xtest_bin = utils.bin_features(Xtest)\n",
    "\n",
    "# find good lambda by cross validation for these three sets\n",
    "\n",
    "def run_dataset(X,ytrain,Xt,ytest,type,penalty):\n",
    "\n",
    "    best_lambda = utils.select_lambda_crossval(X,ytrain,0.1,5.1,0.5,penalty)\n",
    "    print \"best_lambda = \", best_lambda\n",
    "\n",
    "    # train a classifier on best_lambda and run it\n",
    "    if penalty == \"l2\":\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='lbfgs',fit_intercept=True)\n",
    "    else:\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='liblinear',fit_intercept=True)\n",
    "    lreg.fit(X,ytrain)\n",
    "    print \"Coefficients = \", lreg.intercept_,lreg.coef_\n",
    "    predy = lreg.predict(Xt)\n",
    "    print \"Accuracy on set aside test set for \", type, \" = \", np.mean(predy==ytest)\n",
    "\n",
    "print \"L2 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l2\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l2\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l2\")\n",
    "\n",
    "print \"L1 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l1\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l1\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
